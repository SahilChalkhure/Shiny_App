# Calculate the degree of each node
degree_vector <- degree(graph)
# Assuming 'departments' is available as a vector or within a list, we assign it correctly
# Let's assume departments is a separate vector
if (exists("departments")) {
dept_colors <- as.numeric(as.factor(departments))
} else {
stop("Departments vector not found in the loaded data.")
}
# Define a color palette
colors <- categorical_pal(8)
# Map department numbers to colors
node_colors <- colors[dept_colors]
# Plot the graph
plot(graph,
vertex.size = degree_vector * 2,  # Adjust node size (degree * 2 for better visibility)
vertex.color = node_colors,
vertex.label = NA,  # No labels for clarity
main = "Network Graph: Node Size by Degree, Node Color by Department")
# Add a legend for the departments
legend("topright",
legend = levels(as.factor(departments)),
col = colors[1:length(unique(departments))],
pch = 19,
title = "Departments")
# Create a graph object from the adjacency matrix
graph <- graph_from_adjacency_matrix(Y, mode = "undirected")
# Calculate various centrality measures
degree_centrality <- degree(graph)
betweenness_centrality <- betweenness(graph)
closeness_centrality <- closeness(graph)
eigenvector_centrality <- eigen_centrality(graph)$vector
# Combine centrality measures into a data frame for easy comparison
centrality_measures <- data.frame(
Node = 1:vcount(graph),
Degree = degree_centrality,
Betweenness = betweenness_centrality,
Closeness = closeness_centrality,
Eigenvector = eigenvector_centrality
)
# Display the most central nodes based on each measure
most_central_by_degree <- centrality_measures[which.max(degree_centrality),]
most_central_by_betweenness <- centrality_measures[which.max(betweenness_centrality),]
most_central_by_closeness <- centrality_measures[which.max(closeness_centrality),]
most_central_by_eigenvector <- centrality_measures[which.max(eigenvector_centrality),]
cat("Most central node by degree:", most_central_by_degree$Node, "\n")
cat("Most central node by betweenness:", most_central_by_betweenness$Node, "\n")
cat("Most central node by closeness:", most_central_by_closeness$Node, "\n")
cat("Most central node by eigenvector:", most_central_by_eigenvector$Node, "\n")
# Sum up degrees for each department
dept_degree_sums <- tapply(degree_centrality, departments, sum)
highest_aggregated_degree_dept <- which.max(dept_degree_sums)
cat("Department with the highest aggregated degree:", names(dept_degree_sums)[highest_aggregated_degree_dept], "\n")
# Create a table of degree counts
degree_table <- table(degree_centrality)
degrees <- as.numeric(names(degree_table))
counts <- as.numeric(degree_table)
# Log-transform the degrees and their frequencies
log_degrees <- log(degrees)
log_counts <- log(counts)
# Fit a linear model to the log-transformed data
power_law_fit <- lm(log_counts ~ log_degrees)
# Extract the slope (alpha) and intercept
alpha <- -coef(power_law_fit)[2]
intercept <- coef(power_law_fit)[1]
# Plot the degree distribution and the power-law fit
plot(log_degrees, log_counts, main = "Log-Log Degree Distribution", xlab = "Log(Degree)", ylab = "Log(Frequency)")
abline(power_law_fit, col = "red")
# Print the parameters of the power-law fit
cat("Power-law fit: alpha =", alpha, "intercept =", intercept, "\n")
# Check for assortativity by degree
assortativity_coeff <- assortativity_degree(graph, directed = FALSE)
cat("Assortativity coefficient:", assortativity_coeff, "\n")
# Interpret the results
if (assortativity_coeff > 0) {
cat("The network exhibits assortative mixing by degree (positive assortativity coefficient).\n")
} else if (assortativity_coeff < 0) {
cat("The network exhibits disassortative mixing by degree (negative assortativity coefficient).\n")
} else {
cat("The network exhibits neutral mixing by degree (assortativity coefficient close to 0).\n")
}
quarto check
install.packages("devtools")
install.packages("roxygen2")
print(hello World)
print("Hello World")
has_devel()
create("myRpackage")
create("myRpackage")
create("myRpackage")
usethis::create_package("HDIAnalyzer")
library(devtools)
library(usethis)
library(devtools)
has_devel()
create("myRpackage")
1
create("Flash")
1
create("Flash3")
1
create("Flash3")
create("Flash3")1
create("Flash3")
# Load the necessary libraries
library(igraph)
library(Matrix)
library(cluster)
library(mclust)  # For adjustedRandIndex function
install.packages("mclust")
# Load the necessary libraries
library(igraph)
library(Matrix)
library(ggplot2)
library(reshape2)
install.packages("reshape2")
# Load the necessary libraries
library(igraph)
library(Matrix)
library(ggplot2)
library(reshape2)
# Load the data
load("data_workplace.RData")
# Load the necessary libraries
library(igraph)
library(Matrix)
library(ggplot2)
library(reshape2)
# Load the data
load("data_workplace.RData")
# Assuming the adjacency matrix is named Y and department affiliations are named departments
Y <- as.matrix(Y)
departments <- factor(departments)  # Ensure department is a factor
# Create a graph from the adjacency matrix
g <- graph_from_adjacency_matrix(Y, mode = "undirected")
# Calculate the Laplacian matrix
L <- laplacian_matrix(g)
# Perform eigen decomposition
eig <- eigen(L)
# Plot the eigenvalues to decide the number of clusters
plot(eig$values, type = "b", main = "Eigenvalues of the Laplacian matrix", xlab = "Index", ylab = "Eigenvalue")
# Assuming we choose k=3 clusters based on the eigenvalue plot
k <- 3
U <- eig$vectors[,2:(k+1)]
# Perform k-means clustering on the selected eigenvectors
clustering <- kmeans(U, centers = k)$cluster
# Set up plot parameters for a larger and clearer plot
par(mar = c(0, 0, 2, 0))  # Adjust margins
# Label only a subset of the vertices (e.g., the first 10 vertices in each cluster)
labels <- rep(NA, length(clustering))
for (i in 1:k) {
cluster_indices <- which(clustering == i)
labels[cluster_indices[1:min(10, length(cluster_indices))]] <- V(g)$name[cluster_indices[1:min(10, length(cluster_indices))]]
}
# Load the necessary libraries
library(igraph)
library(Matrix)
library(ggplot2)
library(reshape2)
# Load the data
load("data_workplace.RData")
# Assuming the adjacency matrix is named Y and department affiliations are named departments
Y <- as.matrix(Y)
departments <- factor(departments)  # Ensure department is a factor
# Create a graph from the adjacency matrix
g <- graph_from_adjacency_matrix(Y, mode = "undirected")
# Calculate the Laplacian matrix
L <- laplacian_matrix(g)
# Perform eigen decomposition
eig <- eigen(L)
# Plot the eigenvalues to decide the number of clusters
plot(eig$values, type = "b", main = "Eigenvalues of the Laplacian matrix", xlab = "Index", ylab = "Eigenvalue")
# Assuming we choose k=3 clusters based on the eigenvalue plot
k <- 3
U <- eig$vectors[,2:(k+1)]
# Perform k-means clustering on the selected eigenvectors
clustering <- kmeans(U, centers = k)$cluster
# Set up plot parameters for a larger and clearer plot
par(mar = c(0, 0, 2, 0))  # Adjust margins
plot(g,
vertex.color = clustering,
main = "Spectral Clustering Results",
vertex.size = 10,  # Increase vertex size for better visibility
vertex.label = NA,  # Remove vertex labels if cluttered
edge.arrow.size = 0.5,  # Adjust edge arrow size
layout = layout_with_fr)  # Use Fruchterman-Reingold layout for better spacing
# Create a confusion matrix
confusion_matrix <- table(Cluster = clustering, Department = departments)
print(confusion_matrix)
# Load the necessary libraries
library(igraph)
library(Matrix)
library(ggplot2)
library(reshape2)
# Load the data
load("data_workplace.RData")
# Assuming the adjacency matrix is named Y and department affiliations are named departments
Y <- as.matrix(Y)
departments <- factor(departments)  # Ensure department is a factor
# Create a graph from the adjacency matrix
g <- graph_from_adjacency_matrix(Y, mode = "undirected")
# Calculate the Laplacian matrix
L <- laplacian_matrix(g)
# Perform eigen decomposition
eig <- eigen(L)
# Plot the eigenvalues to decide the number of clusters
plot(eig$values, type = "b", main = "Eigenvalues of the Laplacian matrix", xlab = "Index", ylab = "Eigenvalue")
# Assuming we choose k=3 clusters based on the eigenvalue plot
k <- 3
U <- eig$vectors[,2:(k+1)]
# Perform k-means clustering on the selected eigenvectors
clustering <- kmeans(U, centers = k)$cluster
# Set up plot parameters for a larger and clearer plot
par(mar = c(0, 0, 2, 0))  # Adjust margins
plot(g,
vertex.color = clustering,
main = "Spectral Clustering Results",
vertex.size = 10,  # Increase vertex size for better visibility
vertex.label = NA,  # Remove vertex labels if cluttered
edge.arrow.size = 0.5,  # Adjust edge arrow size
layout = layout_with_fr)  # Use Fruchterman-Reingold layout for better spacing
# Create a confusion matrix
confusion_matrix <- table(Cluster = clustering, Department = departments)
print(confusion_matrix)
# Function to estimate connection probabilities for SBM
estimate_sbm <- function(adj_matrix, class_vector) {
unique_classes <- unique(class_vector)
k <- length(unique_classes)
block_probs <- matrix(0, nrow = k, ncol = k)
class_indices <- split(seq_along(class_vector), class_vector)
for (i in seq_along(unique_classes)) {
for (j in seq_along(unique_classes)) {
class_i <- class_indices[[i]]
class_j <- class_indices[[j]]
sub_matrix <- adj_matrix[class_i, class_j]
block_probs[i, j] <- mean(sub_matrix)
}
}
colnames(block_probs) <- unique_classes
rownames(block_probs) <- unique_classes
return(block_probs)
}
# Estimate the connection probabilities
block_connection_probs <- estimate_sbm(Y, departments)
print(block_connection_probs)
# Visualize the connection probabilities
image(1:nrow(block_connection_probs), 1:ncol(block_connection_probs), t(block_connection_probs),
xlab = "Departments", ylab = "Departments", main = "Block Connection Probabilities",
axes = FALSE, col = heat.colors(256))
axis(1, at = 1:nrow(block_connection_probs), labels = colnames(block_connection_probs))
axis(2, at = 1:ncol(block_connection_probs), labels = rownames(block_connection_probs))
# Load necessary libraries
library(blockmodels)
# Load necessary libraries
library(blockmodels)
install.packages("blockmodels")
# Load necessary libraries
library(blockmodels)
library(mclust)  # For adjustedRandIndex function
# Convert adjacency matrix to igraph object
graph <- graph_from_adjacency_matrix(Y, mode = "undirected")
# Fit the Stochastic Block Model using the Bernoulli model
sbm_fit <- BM_bernoulli(membership_type = "SBM", adj = Y)
sbm_fit$estimate()  # Ensure the model is estimated
# Check the structure of the fitted SBM
str(sbm_fit)
sbm_clusters <- apply(sbm_fit$memberships[[which.max(sbm_fit$ICL)]], 1, which.max)
# Load the necessary libraries
library(blockmodels)
library(mclust)  # For adjustedRandIndex function
# Load the data
load("data_workplace.RData")
departments_data <- read.csv("departments.csv")
# Load the necessary libraries
library(blockmodels)
library(mclust)  # For adjustedRandIndex function
# Fit the Stochastic Block Model using the Bernoulli model
sbm_fit <- BM_bernoulli(membership_type = "SBM", adj = Y)
sbm_fit$estimate()  # Ensure the model is estimated
# Check the structure of the fitted SBM
str(sbm_fit)
# Check if the memberships list and ICL values are correctly populated
if (length(sbm_fit$memberships) > 0 && length(sbm_fit$ICL) > 0) {
# Ensure that the memberships list has valid dimensions
memberships <- sbm_fit$memberships[[which.max(sbm_fit$ICL)]]
if (!is.null(dim(memberships))) {
# Get the clustering result from the SBM fit
sbm_clusters <- apply(memberships, 1, which.max)
} else {
stop("The memberships object does not have valid dimensions.")
}
} else {
stop("The SBM fitting did not produce valid memberships or ICL values. Please check the fitting process.")
}
#loading required libraries
suppressMessages(library(igraph))
library(blockmodels)
library(latentnet)
#loading data
load("data_workplace.RData")
print(ls())
dim(Y)
set.seed(1)
#adj <- as.matrix(Y)
eigen_dec <- eigen(Y)
plot(eigen_dec$values)
#first 3 eigenvectors for embedding
embedding <- eigen_dec$vectors[,1:4]
plot(embedding)
#k-means clustering
k <- 3
memberships <- kmeans(embedding, k, nstart = 100)$cluster
#plot the embedding
plot(embedding, col = memberships
, main = "2D Projection with Clusters")
# Define colors for departments
department_labels <- unique(departments)
colors <- categorical_pal(length(department_labels))
# Map departments to colors
node_colors <- colors[as.factor(departments)]
plot(embedding, col = node_colors)
#compare the clustering results with confusion matrix
dep_lab <- departments_labels[departments]
table(dep_lab, memberships)
workplace_graph <- graph_from_adjacency_matrix(Y, mode = "undirected")
#assign the membership
V(workplace_graph)$membership <- memberships
#plot the clustering
plot(workplace_graph, vertex.color = memberships
,layout = layout_with_fr(workplace_graph)
, main = "Graph with Clusters"
,vertex.label.cex = 0.5
)
# res <- make_clusters(g, memberships)
# plot(res, g, layout = layout)
#Laplacian Matrix
#degree matrix
D <- diag(rowSums(Y))
L <- D - Y
eigen_dec_L <- eigen(L)
plot(rev(eigen_dec_L$values), main = "Eigenvalues of Laplacian Matrix", xlab = "Index", ylab = "Eigenvalue")
#first four eigenvectors for embedding from the Laplacian matrix
embedding_L <- eigen_dec_L$vectors[,89:92]
#k-means clustering on the 4-dimensional embedding
memberships_L <- kmeans(embedding_L, 5, nstart = 100)$cluster
#plot the embedding
plot(embedding_L[,1], embedding_L[,2], col = memberships_L, xlab = "First eigenvector", ylab = "Second eigenvector", main = "2D Projection of 4D Embedding from Laplacian")
#plot
plot(workplace_graph, vertex.color = memberships_L
,layout = layout_with_fr(workplace_graph)
,vertex.label.cex = 0.5)
#clustering results
table(dep_lab, memberships_L)
# Number of departments
num_departments <- length(unique(departments))
# Initialize the connection probability matrix
block_probs <- matrix(0, nrow=num_departments, ncol=num_departments)
# Calculate the connection probabilities for each block
for (i in 1:num_departments) {
for (j in 1:num_departments) {
# Get the indices of individuals in department i and j
dept_i <- which(departments == i)
dept_j <- which(departments == j)
# Submatrix of Y for departments i and j
submatrix <- Y[dept_i, dept_j]
# Calculate the connection probability
block_probs[i, j] <- mean(submatrix)
}
}
# Visualize the block connection probabilities
image(block_probs, main="Block Connection Probabilities", xlab="Department", ylab="Department", col=heat.colors(10))
calc_block_prob <- function(network, classes) {
class_labels <- unique(classes)
K <- length(class_labels)
n <- length(classes)
#matrices initialization
edge_counts <- matrix(0, nrow = K, ncol = K)
non_edge_counts <- matrix(0, nrow = K, ncol = K)
for (i in 1:n) {
for (j in 1:n) {
if (i != j) {
node_i <- classes[i]
node_j <- classes[j]
if (network[i, j] == 1) {
edge_counts[node_i, node_j] <- edge_counts[node_i, node_j] + 1
} else {
non_edge_counts[node_i, node_j] <- non_edge_counts[node_i, node_j] + 1
}
}
}
}
# Calculate connection probabilities
block_prob <- edge_counts / (edge_counts + non_edge_counts)
return(block_prob)
}
# Calculate the block connection probabilities
block_prob <- calc_block_prob(Y, departments)
# Visualize the block connection probabilities
image(block_prob, main = "Block Connection Probabilities")
K <- length(unique(departments))
# Discuss the mixing pattern
diag_sum = sum(diag(block_prob))
block_sum = sum(block_prob) / K
diag_sum
block_sum
is_assortative <- sum(diag(block_prob)) > sum(block_prob) / K
is_assortative
mixing_pattern <- if (is_assortative) "Assortative" else "Disassortative"
cat("The mixing pattern is", mixing_pattern, "\n")
#SBM
sbm_fit <- BM_bernoulli("SBM", Y)
sbm_fit$estimate()
ts.plot(sbm_fit$ICL)
ts.plot(sbm_fit$PL)
K_star <- 5
soft_clustering <- sbm_fit$memberships[[K_star]]$Z
hard_clustering <- apply(soft_clustering, 1, which.max)
image(Y[order(hard_clustering),rev(order(hard_clustering))], xaxt = "n", yaxt = "n")
set.seed(23200711)
sbm_fit$memberships[[K_star]]$plot()
sbm_fit$plot_parameters(K_star)
image(Y[order(hard_clustering),rev(order(hard_clustering))], xaxt = "n", yaxt = "n")
1 + 1
#| echo: false
2 * 2
shiny::runApp('C:/Users/sahil/Desktop/SUMMER TRIMESTER/ADV DATA PROG R/PROJECT/Project')
shiny::runApp('C:/Users/sahil/Desktop/SUMMER TRIMESTER/ADV DATA PROG R/PROJECT/Project')
runApp('C:/Users/sahil/Desktop/SUMMER TRIMESTER/ADV DATA PROG R/PROJECT/Project')
runApp('C:/Users/sahil/Desktop/SUMMER TRIMESTER/ADV DATA PROG R/PROJECT/Project')
runApp('C:/Users/sahil/Desktop/SUMMER TRIMESTER/ADV DATA PROG R/PROJECT/Project')
runApp('C:/Users/sahil/Desktop/SUMMER TRIMESTER/ADV DATA PROG R/PROJECT/Project')
runApp('C:/Users/sahil/Desktop/SUMMER TRIMESTER/ADV DATA PROG R/PROJECT/Project')
runApp('C:/Users/sahil/Desktop/SUMMER TRIMESTER/ADV DATA PROG R/PROJECT/Project')
runApp('C:/Users/sahil/Desktop/SUMMER TRIMESTER/ADV DATA PROG R/PROJECT/Project')
runApp('C:/Users/sahil/Desktop/SUMMER TRIMESTER/ADV DATA PROG R/PROJECT/Project')
runApp('C:/Users/sahil/Desktop/SUMMER TRIMESTER/ADV DATA PROG R/PROJECT/Project')
runApp('C:/Users/sahil/Desktop/SUMMER TRIMESTER/ADV DATA PROG R/PROJECT/Project')
shiny::runApp('C:/Users/sahil/Desktop/SUMMER TRIMESTER/ADV DATA PROG R/PROJECT/Project')
runApp('C:/Users/sahil/Desktop/SUMMER TRIMESTER/ADV DATA PROG R/PROJECT/Project')
runApp('C:/Users/sahil/Desktop/SUMMER TRIMESTER/ADV DATA PROG R/PROJECT/Project')
runApp('C:/Users/sahil/Desktop/SUMMER TRIMESTER/ADV DATA PROG R/PROJECT/Project')
runApp('C:/Users/sahil/Desktop/SUMMER TRIMESTER/ADV DATA PROG R/PROJECT/Project')
runApp('C:/Users/sahil/Desktop/SUMMER TRIMESTER/ADV DATA PROG R/PROJECT/Project')
runApp('C:/Users/sahil/Desktop/SUMMER TRIMESTER/ADV DATA PROG R/PROJECT/Project')
runApp('C:/Users/sahil/Desktop/SUMMER TRIMESTER/ADV DATA PROG R/PROJECT/Project')
runApp('C:/Users/sahil/Desktop/SUMMER TRIMESTER/ADV DATA PROG R/PROJECT/Project')
runApp('C:/Users/sahil/Desktop/SUMMER TRIMESTER/ADV DATA PROG R/PROJECT/Project')
runApp('C:/Users/sahil/Desktop/SUMMER TRIMESTER/ADV DATA PROG R/PROJECT/Project')
runApp('C:/Users/sahil/Desktop/SUMMER TRIMESTER/ADV DATA PROG R/PROJECT/Project')
runApp('C:/Users/sahil/Desktop/SUMMER TRIMESTER/ADV DATA PROG R/PROJECT/Project')
runApp('C:/Users/sahil/Desktop/SUMMER TRIMESTER/ADV DATA PROG R/PROJECT/Project')
runApp('C:/Users/sahil/Desktop/SUMMER TRIMESTER/ADV DATA PROG R/PROJECT/Project')
runApp('C:/Users/sahil/Downloads/Old_Faithful_Basic.R')
runApp('C:/Users/sahil/Downloads/Old_Faithful_Advanced.R')
runApp('C:/Users/sahil/Downloads/Old_Faithful_More_Advanced.R')
runApp('C:/Users/sahil/Desktop/SUMMER TRIMESTER/ADV DATA PROG R/PROJECT/Project')
runApp('C:/Users/sahil/Downloads/Old_Faithful_More_Advanced.R')
library(shiny)
library(shinythemes)
library(tidyverse)
library(DT)
library(plotly)
# Function to load data and create a mapping of country codes to display names
load_and_map_data <- function(file_path) {
data <- read_csv(file_path, col_types = cols(
country_code = col_character(),
country_name = col_character(),
indicator_id = col_character(),
indicator_name = col_character(),
index_id = col_character(),
index_name = col_character(),
value = col_character(),  # Read as character to handle cleaning
year = col_character()    # Read as character to handle cleaning
))
# Print parsing problems if any
if (nrow(problems(data)) > 0) {
print(problems(data))
}
# Clean the value and year columns
data <- data %>%
mutate(
value = as.numeric(gsub("[^0-9.]", "", value)),
year = as.numeric(gsub("[^0-9]", "", year))
) %>%
filter(!is.na(year) & year >= 1900 & year <= as.numeric(format(Sys.Date(), "%Y")))  # Keep only valid years
country_code <- str_extract(basename(file_path), "(?<=_)[A-Za-z]+(?=\\.csv)")
country_name <- case_when(
country_code == "ind" ~ "INDIA",
country_code == "irl" ~ "IRELAND",
country_code == "nga" ~ "NIGERIA",
country_code == "jpn" ~ "JAPAN",
country_code == "sgp" ~ "SINGAPORE",
country_code == "fra" ~ "FRANCE",
country_code == "khm" ~ "CAMBODIA",
TRUE ~ toupper(country_code)
)
data <- data %>% mutate(country_code = country_code, country = country_name)
return(data)
}
# Load built-in datasets
data_files <- list.files("data", pattern = "\\.csv$", full.names = TRUE)
hd_data <- map_dfr(data_files, load_and_map_data)
# Remove any invalid country names
hd_data <- hd_data %>% filter(!str_detect(country, "#country\\+name"))
hd_data <<- hd_data %>% filter(!str_detect(country, "#country\\+name"))  # Remove any invalid country names
updateSelectInput(session, "plot1_y", choices = setdiff(names(hd_data), exclude_cols))
updateSelectInput(session, "indicatorsPlot1", choices = unique(hd_data$indicator_name))
runApp('C:/Users/sahil/Desktop/SUMMER TRIMESTER/ADV DATA PROG R/PROJECT/Project')
runApp('C:/Users/sahil/Desktop/SUMMER TRIMESTER/ADV DATA PROG R/PROJECT/Project')
runApp('C:/Users/sahil/Downloads/Old_Faithful_Advanced.R')
runApp('C:/Users/sahil/Desktop/SUMMER TRIMESTER/ADV DATA PROG R/PROJECT/Project')
runApp('C:/Users/sahil/Desktop/SUMMER TRIMESTER/ADV DATA PROG R/PROJECT/Project')
